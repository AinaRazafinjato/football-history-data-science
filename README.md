# ğŸ† Football History Data Science Project

A comprehensive data science project for analyzing football (soccer) match data across multiple leagues and seasons. This project combines web scraping, data processing, exploratory analysis, and predictive modeling to extract insights from historical football data.

## ğŸ” Project Overview

This project aims to:
- ğŸ“Š Create a comprehensive database of football statistics from multiple leagues
- ğŸ§¹ Clean and standardize data for analysis
- ğŸ“ˆ Analyze performance trends of clubs and leagues
- ğŸ”‘ Identify key success factors in football performance
- ğŸ”® Build predictive models for match outcomes
- ğŸ“‰ Visualize insights through notebooks and reports

## ğŸ“ Project Structure

```
football_history/
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ raw/              # Raw data from web scraping
â”‚   â”‚   â””â”€â”€ *.csv         # Raw league data files
â”‚   â”œâ”€â”€ processed/        # Cleaned and standardized data
â”‚   â”‚   â””â”€â”€ *-processed.csv # Processed league data files
â”‚   â””â”€â”€ results/          # Results from models and analyses
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ data/             # Data preprocessing functions
â”‚   â”‚   â”œâ”€â”€ logs/         # Log folder for data processing
â”‚   â”‚   â”‚   â””â”€â”€ *.log     # Log files for processing
â”‚   â”‚   â”œâ”€â”€ process_csv.py# Main data processing script
â”‚   â”‚   â”œâ”€â”€ config_csv.yaml# Configuration for processing
â”‚   â”‚   â””â”€â”€ README.md     # Usage examples for processing
â”‚   â”œâ”€â”€ scraping/         # Web scraping functionality
â”‚   â”‚   â”œâ”€â”€ logs/         # Log folder for scraping
â”‚   â”‚   â”‚   â””â”€â”€ *.log     # Log files for scraping
â”‚   â”‚   â”œâ”€â”€ scrapers.py   # WebScraper class for data collection
â”‚   â”‚   â”œâ”€â”€ main.py       # Script to run the scraper
â”‚   â”‚   â”œâ”€â”€ config_url.yaml# Configuration for scraping
â”‚   â”‚   â””â”€â”€ README.md     # Usage examples for scraping
â”œâ”€â”€ tests/                # Unit tests
â”‚   â”œâ”€â”€ test_scraping.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ .gitignore            # Git ignore file
â”œâ”€â”€ LICENSE               # Project license
â”œâ”€â”€ README.md             # Project overview and instructions
â””â”€â”€ requirements.txt      # Project dependencies
```

## âš™ï¸ Installation

To set up the project:

```bash
# Clone the repository
git clone https://github.com/yourusername/football_history.git
cd football_history

# Create a virtual environment (optional but recommended)
python -m venv .env

# Activate the virtual environment
# On Windows
.env\Scripts\activate
# On macOS/Linux
source .env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸš€ Usage

### ğŸŒ Data Collection
The project uses web scraping to collect football match data from fbref.com. The main script is located in `src.scraping.main.py`.:

```bash
# Basic usage - scrape default league
python -m src.scraping.main

# Scrape a specific league
python -m src.scraping.main --league premier_league

# Scrape all configured leagues
python -m src.scraping.main --all

# Use a custom URL
python -m src.scraping.main --url "https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures"
```

### ğŸ§® Data Processing
Process raw CSV files into standardized formats:

```bash
# Process a specific file
python -m src.data.process_csv --csv "path/to/file.csv"

# Process all CSV files in the raw folder
python -m src.data.process_csv --all

# Run with verbose output
python -m src.data.process_csv --verbose
```

### ğŸ“Š Analysis
Run exploratory analysis using the Jupyter notebook:

- ğŸ”¬ Open `exploratory_analysis.ipynb` to explore data distributions, correlations, and trends.
- ğŸ“ Evaluate predictive models: Open `model_evaluation.ipynb` to see model performance comparisons.

## âš™ï¸ Configuration
The project uses configuration files to control data processing:

- `config_url.yaml` - Controls web scraping behavior:
    - ğŸ”— League URLs
    - ğŸ“‹ Data extraction rules
    - ğŸ“ Logging settings
    - âš ï¸ Error handling settings
- `config_csv.yaml` - Controls CSV processing behavior:
    - ğŸ“‘ Column specifications
    - ğŸ¢ Team name normalization
    - ğŸ“‚ File paths and patterns
    - ğŸ”„ Processing workflow
    - ğŸ“ Logging settings


## ğŸ’» Tech Stack
- **Data Collection**: ğŸ•·ï¸ Python web scraping with pandas
- **Data Processing**: ğŸ¼ Pandas, ğŸ”¢ NumPy
- **Analysis**: ğŸ§  Scikit-learn, ğŸ“Š Matplotlib, ğŸŒŠ Seaborn
- **Testing**: ğŸ” Unittest, âœ… pytest

## ğŸš§ Current Status
This project is in active development with ongoing work on data collection and preprocessing pipelines.

## ğŸ‘¥ Contributing
Contributions are welcome! Please submit pull requests or open issues for any suggestions.

## ğŸ“„ License
This project is licensed under the MIT License.